ggtitle("Correlation Heatmap") +
theme(plot.title = element_text(hjust = 0.5))
IMDB$binned_score <- cut(IMDB$imdb_score, breaks = c(0,3,6,8,10))
# See whether the data is balanced or unbalanced?
plot(IMDB$binned_score, main = "Number of observations in each classs")
table(IMDB$binned_score)
# Rearrange the columns and column name
IMDB <- IMDB[,c(9,4,5,14,12,2,3,13,1,6,10,7,8,11,15)]
colnames(IMDB) <- c("budget", "gross", "user_vote", "critic_review_ratio",
"movie_fb", "director_fb", "actor1_fb", "other_actors_fb",
"duration", "face_number", "year", "country", "content_rating",
"imdb_score", "binned_score")
dim(IMDB)
set.seed(45)
train.index <- sample(row.names(IMDB), dim(IMDB)[1]*0.8)
test.index <- setdiff(row.names(IMDB), train.index)
train <- IMDB[train.index, ]
test <- IMDB[test.index, ]
dim(train)
dim(test)
library(rpart)
library(rpart.plot)
set.seed(51)
class.tree <- rpart(binned_score ~ . -imdb_score, data = train, method = "class")
class.tree
prp(class.tree, type = 1, extra = 1, under = TRUE, split.font = 2, varlen = 0)
class.tree.pred <- predict(class.tree, test, type = "class")
confusionMatrix(class.tree.pred, test$binned_score)
set.seed(51)
cv.ct <- rpart(binned_score ~ . -imdb_score, data = train, method = "class", cp = 0.00001, minsplit = 5, xval = 5)
printcp(cv.ct)
plotcp(cv.ct)
# prune by lowest cp
set.seed(51)
pruned.ct <- prune(cv.ct,
cp = cv.ct$cptable[which.min(cv.ct$cptable[,"xerror"]),"CP"])
length(pruned.ct$frame$var[pruned.ct$frame$var == "<leaf>"])
prp(pruned.ct, type = 1, extra = 1, split.font = 1, varlen = -10)
# apply model on test set
tree.pred.test <- predict(pruned.ct, test, type = "class")
# generate confusion matrix for test data
confusionMatrix(tree.pred.test, test$binned_score)
set.seed(53)
bag <- randomForest(binned_score ~ . -imdb_score, data = train, mtry = 15)
bag.pred <- predict(bag, test)
confusionMatrix(bag.pred, test$binned_score)
# Show model error
plot(bag)
legend('topright', colnames(bag$err.rate), col=1:5, fill=1:5)
importance <- importance(bag)
varImportance <- data.frame(Variables = row.names(importance),
Importance = round(importance[ ,'MeanDecreaseGini'],2))
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance))))
# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance, fill = Importance)) +
geom_bar(stat='identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust=0, vjust=0.55, size = 4, colour = 'red') +
labs(x = 'Variables') +
coord_flip() +
theme_few()
set.seed(53)
rf <- randomForest(binned_score ~ . -imdb_score, data = train, mtry = sqrt(15))
rf.pred <- predict(rf, test)
confusionMatrix(rf.pred, test$binned_score)
# Show model error
plot(rf)
legend('topright', colnames(rf$err.rate), col=1:5, fill=1:5)
importance <- importance(rf)
varImportance <- data.frame(Variables = row.names(importance),
Importance = round(importance[ ,'MeanDecreaseGini'],2))
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance))))
# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance, fill = Importance)) +
geom_bar(stat='identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust=0, vjust=0.55, size = 4, colour = 'red') +
labs(x = 'Variables') +
coord_flip() +
theme_few()
library(FNN)
# Use model.matrix() to create dummy variables for country and content.
IMDB2 <- IMDB
IMDB2$country <- as.factor(IMDB2$country)
IMDB2$content <- as.factor(IMDB2$content)
IMDB2[,c("country_UK", "country_USA", "country_Others")] <- model.matrix( ~ country - 1, data = IMDB2)
IMDB2[,c("content_G", "content_NC17", "content_PG", "content_PG13", "content_R")] <- model.matrix( ~ content - 1, data = IMDB2)
IMDB2$gross <- as.numeric(IMDB2$gross)
IMDB2$user_vote <- as.numeric(IMDB2$user_vote)
IMDB2$year <- as.numeric(IMDB2$year)
# Select useful variables for future prediction.
IMDB2 <- IMDB2[, c(1,2,3,4,5,6,7,8,9,10,11,17,18,19,20,21,22,23,24,15)]
str(IMDB2)
# Partition the data into training and validation sets.
set.seed(52)
train2 <- IMDB2[train.index, ]
test2 <- IMDB2[test.index, ]
# initialize normalized training, validation, test data, complete data frames to originals
train2.norm <- train2
test2.norm <- test2
IMDB2.norm <- IMDB2
# use preProcess() from the caret package to normalize predictors.
norm.values <- preProcess(train2[, -20], method=c("center", "scale"))
train2.norm[, -20] <- predict(norm.values, train2[, -20])
test2.norm[, -20] <- predict(norm.values, test2[, -20])
IMDB2.norm[, -20] <- predict(norm.values, IMDB2[, -20])
train2.norm
# initialize a data frame with two columns: k, and accuracy.
accuracy.df <- data.frame(k = seq(1, 30, 1), accuracy = rep(0, 30))
# compute knn for different k on validation data.
for(i in 1:30) {
knn.pred <- knn(train2.norm[, 1:19], test2.norm[, 1:19],
cl = train2.norm[, 20], k = i)
accuracy.df[i, 2] <- confusionMatrix(knn.pred, test2.norm[, 20])$overall[1]
}
accuracy.df
plot(accuracy.df$k, accuracy.df$accuracy, type = "b")
which.max(accuracy.df$accuracy)
# apply model on test set
knn.pred.test <- knn(train2.norm[, -20], test2.norm[, -20],
cl = train2.norm[, 20], k = 7)
# generate confusion matrix for test data
confusionMatrix(knn.pred.test, test2.norm$binned_score)
View(genres)
View(genres.df)
View(genres.df)
set.seed(51)
class.tree <- rpart(binned_score ~ . -imdb_score, data = train, method = "class")
class.tree
prp(class.tree, type = 1, extra = 1, under = TRUE, split.font = 2, varlen = 0, main="Unpruned Classification Tree")
# prune by lowest cp
set.seed(51)
pruned.ct <- prune(cv.ct,
cp = cv.ct$cptable[which.min(cv.ct$cptable[,"xerror"]),"CP"])
length(pruned.ct$frame$var[pruned.ct$frame$var == "<leaf>"])
prp(pruned.ct, type = 1, extra = 1, split.font = 1, varlen = -10, main = "Pruned Classification Tree")
set.seed(53)
rf <- randomForest(binned_score ~ . -imdb_score, data = train, mtry = sqrt(15))
rf.pred <- predict(rf, test)
confusionMatrix(rf.pred, test$binned_score)
# Show model error
plot(rf)
legend('topright', colnames(rf$err.rate), col=1:5, fill=1:5)
set.seed(53)
bag <- randomForest(binned_score ~ . -imdb_score, data = train, mtry = 15)
bag.pred <- predict(bag, test)
confusionMatrix(bag.pred, test$binned_score)
# Show model error
plot(bag)
legend('topright', colnames(bag$err.rate), col=1:5, fill=1:5)
set.seed(53)
rf <- randomForest(binned_score ~ . -imdb_score, data = train, mtry = sqrt(15))
rf.pred <- predict(rf, test)
confusionMatrix(rf.pred, test$binned_score)
# Show model error
plot(rf,main = "Random Forest")
legend('topright', colnames(rf$err.rate), col=1:5, fill=1:5)
set.seed(53)
bag <- randomForest(binned_score ~ . -imdb_score, data = train, mtry = 15)
bag.pred <- predict(bag, test)
confusionMatrix(bag.pred, test$binned_score)
# Show model error
plot(bag, main = "Bagging")
legend('topright', colnames(bag$err.rate), col=1:5, fill=1:5)
par(mfrow = c(1,2))
plot(bag, main = "Bagging")
plot(rf,main = "Random Forest")
par(mfrow = c(1,2))
plot(bag, main = "Bagging")
legend('topright', colnames(bag$err.rate), col=1:5, fill=1:5)
plot(rf,main = "Random Forest")
legend('topright', colnames(rf$err.rate), col=1:5, fill=1:5)
par(mfrow = c(1,2))
importance <- importance(bag)
importance <- importance(rf)
par(mfrow = c(1,2))
importance <- importance(bag)
varImportance <- data.frame(Variables = row.names(importance),
Importance = round(importance[ ,'MeanDecreaseGini'],2))
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance))))
# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance, fill = Importance)) +
geom_bar(stat='identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust=0, vjust=0.55, size = 4, colour = 'red') +
labs(x = 'Variables') +
coord_flip() +
theme_few()
importance <- importance(rf)
par(mfrow = c(1,2))
importance <- importance(bag)
varImportance <- data.frame(Variables = row.names(importance),
Importance = round(importance[ ,'MeanDecreaseGini'],2))
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance))))
# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance, fill = Importance)) +
geom_bar(stat='identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust=0, vjust=0.55, size = 4, colour = 'red') +
labs(x = 'Variables') +
coord_flip() +
theme_few()
importance <- importance(rf)
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance))))
# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance, fill = Importance)) +
geom_bar(stat='identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust=0, vjust=0.55, size = 4, colour = 'red') +
labs(x = 'Variables') +
coord_flip() +
theme_few()
# initialize a data frame with two columns: k, and accuracy.
accuracy.df <- data.frame(k = seq(1, 30, 1), accuracy = rep(0, 30))
# compute knn for different k on validation data.
for(i in 1:30) {
knn.pred <- knn(train2.norm[, 1:19], test2.norm[, 1:19],
cl = train2.norm[, 20], k = i)
accuracy.df[i, 2] <- confusionMatrix(knn.pred, test2.norm[, 20])$overall[1]
}
accuracy.df
plot(accuracy.df$k, accuracy.df$accuracy, type = "b")
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2) # visualization
library(ggrepel)
library(ggthemes) # visualization
library(scales) # visualization
library(dplyr) # data manipulation
library(VIM)
library(data.table)
library(formattable)
library(plotly)
library(corrplot)
library(GGally)
library(caret)
library(car)
getwd()
setwd("/Users/zhumanhui/Desktop/565 Project")
IMDB <- read.csv("movie_metadata.csv")
dim(IMDB)
str(IMDB)
# Remove the 45 duplicated rows and keep the unique ones
sum(duplicated(IMDB))
# Delete the duplicate rows
IMDB <- IMDB[!duplicated(IMDB),]
dim(IMDB)
head(IMDB)
# remove the whitespace and special character(Â) in the movie title
library(stringr)
IMDB$movie_title <- gsub("Â", "", as.character(factor(IMDB$movie_title)))
str_trim(IMDB$movie_title, side = "right")
head(IMDB$genres)
# Each genres have various types, first we need to divide the string and save each substring along with its corresponding IMDB score in the other data frame genres.df.
# create a new data frame of genres
genres.df <- as.data.frame(IMDB[,c("genres", "imdb_score")])
# set factor for categorical variables (each type) and separate different genres into new columns
genres.df$Action <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Action") 1 else 0)
genres.df$Adventure <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Adventure") 1 else 0)
genres.df$Animation <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Animation") 1 else 0)
genres.df$Biography <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Biography") 1 else 0)
genres.df$Comedy <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Comedy") 1 else 0)
genres.df$Crime <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Crime") 1 else 0)
genres.df$Documentary <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Documentary") 1 else 0)
genres.df$Drama <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Drama") 1 else 0)
genres.df$Family <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Family") 1 else 0)
genres.df$Fantasy <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Fantasy") 1 else 0)
genres.df$`Film-Noir` <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Film-Noir") 1 else 0)
genres.df$History <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "History") 1 else 0)
genres.df$Horror <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Horror") 1 else 0)
genres.df$Musical <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Musical") 1 else 0)
genres.df$Mystery <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Mystery") 1 else 0)
genres.df$News <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "News") 1 else 0)
genres.df$Romance <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Romance") 1 else 0)
genres.df$`Sci-Fi` <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Sci-Fi") 1 else 0)
genres.df$Short <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Short") 1 else 0)
genres.df$Sport <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Sport") 1 else 0)
genres.df$Thriller <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Thriller") 1 else 0)
genres.df$War <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "War") 1 else 0)
genres.df$Western <- sapply(1:length(genres.df$genres), function(x) if (genres.df[x,1] %like% "Western") 1 else 0)
# find the mean of imdb score for different genres
means <- rep(0,23)
for (i in 1:23) {
means[i] <- mean(genres.df$imdb_score[genres.df[i+2]==1])
}
means
# plot the imdb score means vs. types
barplot(means, main = "Average imdb scores for different genres", ylab= "Average IMDB scores", xlab="genres")
IMDB <- subset(IMDB, select = -c(genres))
dim(IMDB)
# find the missing values and aggregate NA in each column
colSums(sapply(IMDB, is.na))
# use heatmap to visualize missing values
missing.values <- aggr(IMDB, sortVars = T, prop = T, sortCombs = T, cex.lab = 1.5, cex.axis = .6, cex.numbers = 5, combined = F, gap = -.2)
IMDB <- IMDB[!is.na(IMDB$gross), ]
IMDB <- IMDB[!is.na(IMDB$budget), ]
dim(IMDB)
sum(complete.cases(IMDB))
3857 - 3768
table(IMDB$aspect_ratio)
IMDB$aspect_ratio[is.na(IMDB$aspect_ratio)] <- 0
mean(IMDB$imdb_score[IMDB$aspect_ratio == 1.85])
mean(IMDB$imdb_score[IMDB$aspect_ratio == 2.35])
mean(IMDB$imdb_score[IMDB$aspect_ratio != 1.85 & IMDB$aspect_ratio != 2.35])
# Remove aspect_ratio
IMDB <- subset(IMDB, select = -c(aspect_ratio))
# replace NA with column average for facenumber_in_poster
IMDB$facenumber_in_poster[is.na(IMDB$facenumber_in_poster)] <- round(mean(IMDB$facenumber_in_poster, na.rm = TRUE))
# convert 0s into NAs for other predictors
IMDB[,c(5,6,8,13,24,26)][IMDB[,c(5,6,8,13,24,26)] == 0] <- NA
# impute missing value with column mean
IMDB$num_critic_for_reviews[is.na(IMDB$num_critic_for_reviews)] <- round(mean(IMDB$num_critic_for_reviews, na.rm = TRUE))
IMDB$duration[is.na(IMDB$duration)] <- round(mean(IMDB$duration, na.rm = TRUE))
IMDB$director_facebook_likes[is.na(IMDB$director_facebook_likes)] <- round(mean(IMDB$director_facebook_likes, na.rm = TRUE))
IMDB$actor_3_facebook_likes[is.na(IMDB$actor_3_facebook_likes)] <- round(mean(IMDB$actor_3_facebook_likes, na.rm = TRUE))
IMDB$actor_1_facebook_likes[is.na(IMDB$actor_1_facebook_likes)] <- round(mean(IMDB$actor_1_facebook_likes, na.rm = TRUE))
IMDB$cast_total_facebook_likes[is.na(IMDB$cast_total_facebook_likes)] <- round(mean(IMDB$cast_total_facebook_likes, na.rm = TRUE))
IMDB$actor_2_facebook_likes[is.na(IMDB$actor_2_facebook_likes)] <- round(mean(IMDB$actor_2_facebook_likes, na.rm = TRUE))
IMDB$movie_facebook_likes[is.na(IMDB$movie_facebook_likes)] <- round(mean(IMDB$movie_facebook_likes, na.rm = TRUE))
table(IMDB$content_rating)
# delete the rows that is blank in content_rating
IMDB <- IMDB[!(IMDB$content_rating %in% ""),]
IMDB$content_rating[IMDB$content_rating == 'M']   <- 'PG'
IMDB$content_rating[IMDB$content_rating == 'GP']  <- 'PG'
IMDB$content_rating[IMDB$content_rating == 'X']   <- 'NC-17'
IMDB$content_rating[IMDB$content_rating == 'Approved']  <- 'R'
IMDB$content_rating[IMDB$content_rating == 'Not Rated'] <- 'R'
IMDB$content_rating[IMDB$content_rating == 'Passed']    <- 'R'
IMDB$content_rating[IMDB$content_rating == 'Unrated']   <- 'R'
IMDB$content_rating <- factor(IMDB$content_rating)
table(IMDB$content_rating)
table(IMDB$color)
3680/(124+3680)
IMDB <- subset(IMDB, select = -c(color))
table(IMDB$language)
IMDB <- subset(IMDB, select = -c(language))
table(IMDB$country)
levels(IMDB$country) <- c(levels(IMDB$country), "Others")
IMDB$country[(IMDB$country != 'USA')&(IMDB$country != 'UK')] <- 'Others'
IMDB$country <- factor(IMDB$country)
table(IMDB$country)
ggplot(IMDB, aes(title_year)) +
geom_bar() +
labs(x = "Year movie was released", y = "Movie Count", title = "Histogram of Movie released") +
theme(plot.title = element_text(hjust = 0.5))
table(IMDB$title_year < 1980)
95/(3711+95)
IMDB <- IMDB[IMDB$title_year >= 1980,]
# unique number of directors
sum(uniqueN(IMDB$director_name))
# unique number of actors
sum(uniqueN(IMDB[, c("actor_1_name", "actor_2_name", "actor_3_name")]))
IMDB <- subset(IMDB, select = -c(director_name, actor_2_name, actor_1_name,
movie_title, actor_3_name, plot_keywords,
movie_imdb_link))
# Remove the highly correlated variables
ggcorr(IMDB, label = TRUE, label_round = 2, label_size = 3.5, size = 2, hjust = .85) +
ggtitle("Correlation Heatmap") +
theme(plot.title = element_text(hjust = 0.5))
# add up actor 2 and 3 facebook likes into other actors facebook likes
IMDB$other_actors_facebook_likes <- IMDB$actor_2_facebook_likes + IMDB$actor_3_facebook_likes
# use the ratio of critical reviews amount to total reviews amount
IMDB$critic_review_ratio <- IMDB$num_critic_for_reviews / IMDB$num_user_for_reviews
# delete columns
IMDB <- subset(IMDB, select = -c(cast_total_facebook_likes, actor_2_facebook_likes, actor_3_facebook_likes, num_critic_for_reviews, num_user_for_reviews))
ggcorr(IMDB, label = TRUE, label_round = 2, label_size = 4, size = 3, hjust = .85) +
ggtitle("Correlation Heatmap") +
theme(plot.title = element_text(hjust = 0.5))
IMDB$binned_score <- cut(IMDB$imdb_score, breaks = c(0,3,6,8,10))
plot(IMDB$binned_score, main = "Number of observations in each classs")
table(IMDB$binned_score)
IMDB <- IMDB[,c(9,4,5,14,12,2,3,13,1,6,10,7,8,11,15)]
colnames(IMDB) <- c("budget", "gross", "user_vote", "critic_review_ratio",
"movie_fb", "director_fb", "actor1_fb", "other_actors_fb",
"duration", "face_number", "year", "country", "content_rating",
"imdb_score", "binned_score")
dim(IMDB)
set.seed(45)
train.index <- sample(row.names(IMDB), dim(IMDB)[1]*0.8)
test.index <- setdiff(row.names(IMDB),train.index)
train <- IMDB[train.index, ]
test <- IMDB[test.index, ]
dim(train)
dim(test)
library(rpart)
library(rpart.plot)
set.seed(51)
class.tree <- rpart(binned_score ~ . -imdb_score, data = train, method = "class")
class.tree
prp(class.tree, type = 1, extra = 1, under = TRUE, split.font = 2, varlen = 0)
class.tree.pred <- predict(class.tree, test, type = "class")
confusionMatrix(class.tree.pred, test$binned_score)
set.seed(51)
cv.ct <- rpart(binned_score ~ . -imdb_score, data = train, method = "class", cp = 0.00001, minsplit = 5, xval = 5)
printcp(cv.ct)
plotcp(cv.ct)
# prune by lowest cp
set.seed(51)
pruned.ct <- prune(cv.ct,
cp = cv.ct$cptable[which.min(cv.ct$cptable[,"xerror"]),"CP"])
length(pruned.ct$frame$var[pruned.ct$frame$var == "<leaf>"])
prp(pruned.ct, type = 1, extra = 1, split.font = 1, varlen = -10)
# apply model on training set
tree.pred.train <- predict(pruned.ct, train, type = "class")
# generate confusion matrix for training data
confusionMatrix(tree.pred.train, train$binned_score)
# apply model on test set
tree.pred.test <- predict(pruned.ct, test, type = "class")
# generate confusion matrix for test data
confusionMatrix(tree.pred.test, test$binned_score)
library(FNN)
# Use model.matrix() to create dummy variables for country and content.
IMDB2 <- IMDB
IMDB2$country <- as.factor(IMDB2$country)
IMDB2$content <- as.factor(IMDB2$content)
IMDB2[,c("country_UK", "country_USA", "country_Others")] <- model.matrix( ~ country - 1, data = IMDB2)
IMDB2[,c("content_G", "content_NC17", "content_PG", "content_PG13", "content_R")] <- model.matrix( ~ content - 1, data = IMDB2)
IMDB2$gross <- as.numeric(IMDB2$gross)
IMDB2$user_vote <- as.numeric(IMDB2$user_vote)
IMDB2$year <- as.numeric(IMDB2$year)
# Select useful variables for future prediction.
IMDB2 <- IMDB2[, c(1,2,3,4,5,6,7,8,9,10,11,17,18,19,20,21,22,23,24,15)]
str(IMDB2)
# Partition the data into training and validation sets.
set.seed(52)
train2 <- IMDB2[train.index, ]
test2 <- IMDB2[test.index, ]
# initialize normalized training, validation, test data, complete data frames to originals
train2.norm <- train2
test2.norm <- test2
IMDB2.norm <- IMDB2
# use preProcess() from the caret package to normalize predictors.
norm.values <- preProcess(train2[, -20], method=c("center", "scale"))
train2.norm[, -20] <- predict(norm.values, train2[, -20])
test2.norm[, -20] <- predict(norm.values, test2[, -20])
IMDB2.norm[, -20] <- predict(norm.values, IMDB2[, -20])
train2.norm
# initialize a data frame with two columns: k, and accuracy.
accuracy.df <- data.frame(k = seq(1, 30, 1), accuracy = rep(0, 30))
# compute knn for different k on validation data.
for(i in 1:30) {
knn.pred <- knn(train2.norm[, 1:19], test2.norm[, 1:19],
cl = train2.norm[, 20], k = i)
accuracy.df[i, 2] <- confusionMatrix(knn.pred, test2.norm[, 20])$overall[1]
}
accuracy.df
plot(accuracy.df$k, accuracy.df$accuracy, type = "b")
which.max(accuracy.df$accuracy)
# apply model on test set
knn.pred.test <- knn(train2.norm[, -20], test2.norm[, -20],
cl = train2.norm[, 20], k = 7)
# generate confusion matrix for test data
confusionMatrix(knn.pred.test, test2.norm$binned_score)
library(randomForest)
set.seed(53)
bag <- randomForest(binned_score ~ . -imdb_score, data = train, mtry = 15)
bag.pred <- predict(bag, test)
confusionMatrix(bag.pred, test$binned_score)
# Show model error
plot(bag)
legend('topright', colnames(bag$err.rate), col=1:5, fill=1:5)
importance <- importance(bag)
varImportance <- data.frame(Variables = row.names(importance),
Importance = round(importance[ ,'MeanDecreaseGini'],2))
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance))))
# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance, fill = Importance)) +
geom_bar(stat='identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust=0, vjust=0.55, size = 4, colour = 'red') +
labs(x = 'Variables') +
coord_flip() +
theme_few()
set.seed(53)
rf <- randomForest(binned_score ~ . -imdb_score, data = train, mtry = sqrt(15))
rf.pred <- predict(rf, test)
confusionMatrix(rf.pred, test$binned_score)
# Show model error
plot(rf)
legend('topright', colnames(rf$err.rate), col=1:5, fill=1:5)
importance <- importance(rf)
varImportance <- data.frame(Variables = row.names(importance),
Importance = round(importance[ ,'MeanDecreaseGini'],2))
# Create a rank variable based on importance
rankImportance <- varImportance %>%
mutate(Rank = paste0('#',dense_rank(desc(Importance))))
# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance),
y = Importance, fill = Importance)) +
geom_bar(stat='identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust=0, vjust=0.55, size = 4, colour = 'red') +
labs(x = 'Variables') +
coord_flip() +
theme_few()
